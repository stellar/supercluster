apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}-stellar-core
spec:
  clusterIP: None
  selector:
    app: {{ .Release.Name }}-stellar-core
  ports:
    - port: 11626
      targetPort: 11626
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ .Release.Name }}-sa
  {{- if .Values.service_account.annotations }}
  annotations:
    {{- range .Values.service_account.annotations }}
    {{ .key }}: {{ .value }}
    {{- end }}
  {{- end }}
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ .Release.Name }}-stellar-core
  labels:
    app: {{ .Release.Name }}-stellar-core
spec:
  serviceName: "{{ .Release.Name }}-stellar-core"
  podManagementPolicy: Parallel
  replicas: {{ .Values.worker.replicas }}
  selector:
    matchLabels:
      app: {{ .Release.Name }}-stellar-core
  template:
    metadata:
      labels:
        app: {{ .Release.Name }}-stellar-core
    spec:
      serviceAccountName: {{ .Release.Name }}-sa
      {{- if or .Values.worker.requireNodeLabels .Values.worker.avoidNodeLabels }}
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              {{- range .Values.worker.requireNodeLabels }}
              - key: {{ .key }}
                operator: {{ .operator }}
                {{- with .values }}
                values: {{ toJson . }}
                {{- end }}
              {{- end }}
              {{- range .Values.worker.avoidNodeLabels }}
              - key: {{ .key }}
                operator: {{ .operator }}
                {{- with .values }}
                values: {{ toJson . }}
                {{- end }}
              {{- end }}
      {{- end }}
      {{- if .Values.worker.tolerateNodeTaints }}
      tolerations:
      {{- range .Values.worker.tolerateNodeTaints }}
      - key: {{ .key }}
        effect: {{ .effect }}
      {{- end }}
      {{- end }}
      containers:
      - name: stellar-core
        image: {{ .Values.worker.stellar_core_image }}
        imagePullPolicy: Always
        resources:
          requests:
            cpu: "{{ .Values.worker.resources.requests.cpu}}"
            memory: "{{ .Values.worker.resources.requests.memory}}"
            ephemeral-storage: "{{ .Values.worker.resources.requests.ephemeral_storage}}"
          limits:
            cpu: "{{ .Values.worker.resources.limits.cpu}}"
            memory: "{{ .Values.worker.resources.limits.memory}}"
            ephemeral-storage: "{{ .Values.worker.resources.limits.ephemeral_storage}}"
        command: ["/bin/sh", "/scripts/worker.sh"]
        ports:
        - containerPort: 11626
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: ASAN_OPTIONS
          value: {{ .Values.worker.asanOptions | quote }}
        envFrom:
        - configMapRef:
            name: {{ .Release.Name }}-worker-config
        volumeMounts:
        - name: config
          mountPath: /config
        - name: script
          mountPath: /scripts
        - name: data-volume
          mountPath: /data
      volumes:
      - name: config
        configMap:
          name: {{ .Release.Name }}-stellar-core-config
      - name: script
        configMap:
          name: {{ .Release.Name }}-worker-script
      - emptyDir: {}
        name: data-volume
      {{- if not .Values.worker.unevenSched }}
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app: {{ .Release.Name }}-stellar-core
        # Note: maxSkew affects dynamic node scheduling with karpenter
        # See https://github.com/stellar/supercluster/issues/330
        maxSkew: 2
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      {{- end }}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-worker-script
data:
  worker.sh: |-
    {{- (.Files.Get "files/worker.sh") | nindent 4 }}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-stellar-core-config
data:
  stellar-core.cfg: |-
    {{- if .Values.worker.catchup_skip_known_results_for_testing }}
    {{ "\n" }}
    CATCHUP_SKIP_KNOWN_RESULTS_FOR_TESTING = true
    {{- end }}
    {{- if .Values.worker.check_events_are_consistent_with_entry_diffs }}
    {{ "\n" }}
    EMIT_CLASSIC_EVENTS = true
    BACKFILL_STELLAR_ASSET_EVENTS = true
    INVARIANT_CHECKS = [ "(?!BucketListIsConsistentWithDatabase).*" ]
    {{- else }}
    {{ "\n" }}
    INVARIANT_CHECKS = [ "(?!BucketListIsConsistentWithDatabase|EventsAreConsistentWithEntryDiffs).*" ]
    {{- end }}
    {{- tpl (.Files.Get "files/stellar-core.cfg") . | nindent 4 }}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-worker-config
data:
  REDIS_HOST: "{{ .Values.redis.hostname }}"
  REDIS_PORT: "{{ .Values.redis.port }}"
  JOB_QUEUE: "{{ .Values.redis.job_queue }}"
  SUCCESS_QUEUE: "{{ .Values.redis.success_queue }}"
  FAILED_QUEUE: "{{ .Values.redis.failed_queue }}"
  PROGRESS_QUEUE: "{{ .Values.redis.progress_queue }}"
  METRICS: "{{ .Values.redis.metrics }}"
  RELEASE_NAME: "{{ .Release.Name }}"
